{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.1 Cross-Validating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to evaluate how well my model will work in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964931719428926"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load digits datasets\n",
    "digits = datasets.load_digits()\n",
    "# Create features matrix\n",
    "features = digits.data\n",
    "# Create target vector\n",
    "target = digits.target\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "# Create logistic regression object\n",
    "logit = LogisticRegression()\n",
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# Conduct k-Fold cors-validation\n",
    "cv_results = cross_val_score(pipeline,  # Pipeline\n",
    "                             features,  # Feature matrix\n",
    "                             target,    # Target vector\n",
    "                             cv=kf,     # Corss-validation technique\n",
    "                             scoring='accuracy',  # Loss finction\n",
    "                             n_jobs= -1) # Use all CPU scores\n",
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
       "       0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View score for all 10 folds\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
       "       0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)\n",
    "# Fit standardizer to training set\n",
    "standardizer.fit(features_train)\n",
    "# Apply to both training and test sets\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "# Do k-Fold cross-validation\n",
    "cv_results = cross_val_score(pipeline,  # Pipeline\n",
    "                             features,  # Feature matrix\n",
    "                             target,    # Target vector\n",
    "                             cv=kf,     # Corss-validation technique\n",
    "                             scoring='accuracy',  # Loss finction\n",
    "                             n_jobs= -1) # Use all CPU scores\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.2 Creating a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want a simple baseline regression model to compare against my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "# Create features\n",
    "features, target = boston.data, boston.target\n",
    "# Make test and training split\n",
    "features_train, features_test, target_train, \n",
    "target_test = train_test_split(features, target, random_state=0)\n",
    "# Create a dummy regressor\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "# 'Train' dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "# Get R-squared score\n",
    "dummy.score(features_train, target_train)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5977551962946686"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "# Get R-squared score\n",
    "ols.score(features_train, target_train)\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, we train our model and evaluate the performance score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-29.00527322882046"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy regressor that predicts 20's for everything\n",
    "clf = DummyRegressor(strategy='constant', constant=20)\n",
    "clf.fit(features_train, target_train)\n",
    "# Evaluate score\n",
    "clf.score(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.3 Creating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a simple baseline classifier to compare against your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09956709956709957"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "# Create target vector and feature matrix\n",
    "features, target = iris.data, iris.target\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, \n",
    "target_test = train_test_split(features, target, random_state=0)\n",
    "# Create dummy classifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "# 'Train' model\n",
    "dummy.fit(features_train, target_train)\n",
    "# Get accuracy score\n",
    "dummy.score(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the baseline classifier to our trained classifier, we can see the improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create classifier\n",
    "classifier = RandomForestClassifier()\n",
    "# Train model\n",
    "classifier.fit(features_train, target_train)\n",
    "# Get accuracy score\n",
    "classifier.score(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.4 Evaluating Binary Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a trained classification model, you want to evaluate its quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95170966, 0.9580084 , 0.95558223])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "X, y = make_classification(n_samples=10000,\n",
    "                           n_features=3,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=1)\n",
    "# Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "# Cross-validate model using accuracy\n",
    "cross_val_score(logit, X, y, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95252404, 0.96583282, 0.95558223])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using precision\n",
    "cross_val_score(logit, X, y, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95080984, 0.94961008, 0.95558223])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using recall\n",
    "cross_val_score(logit, X, y, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95166617, 0.95765275, 0.95558223])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using f1\n",
    "cross_val_score(logit, X, y, scoring='f1')\n",
    "# shows that of observations labeled as positive, \n",
    "# how many are actually positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have the true y values and predicted y values, \n",
    "\n",
    "we can calculate metrics like accuracy and recall directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=1)\n",
    "# Predict values for training target vector\n",
    "y_hat = logit.fit(X_train, y_train).predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.5 Evaluating Binary Classifier Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Receving Operating Characteristic (ROC) curve is a common method for evaluating the quality of a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-8ec9127fa86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Create true and false positive rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m false_positve_rate, true_positive_rate, threshold = roc_curve(target_test,\n\u001b[0;32m---> 26\u001b[0;31m                                                               target_probabilities)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# Plot ROC curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Receiver Operating Characteristic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 618\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    395\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    396\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown format is not supported"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=10,\n",
    "                                       n_classes=2,\n",
    "                                       n_informative=3,\n",
    "                                       random_state=3)\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, \n",
    "target_test = train_test_split(features, target, \n",
    "                              test_size=0.1, \n",
    "                              random_state=1)\n",
    "# Create classifier \n",
    "logit = LogisticRegression()\n",
    "# Train model\n",
    "logit.fit(features_train, target_train)\n",
    "# Get predicted probabilities\n",
    "target_probabilities = logit.predict_proba(features_test)[:,1]\n",
    "# Create true and false positive rates\n",
    "false_positve_rate, true_positive_rate, threshold = roc_curve(target_test,\n",
    "                                                              target_probabilities)\n",
    "# Plot ROC curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls='- -')\n",
    "plt.plot([0, 0], [1, 0], c='0.7'), plt.plot([1, 1], c='0.7')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.68520156e-12, 9.63011822e-01, 1.80280831e-07, 3.22834600e-14,\n",
       "        1.95979250e-08, 5.65683254e-07, 2.04782923e-08, 2.99888423e-08,\n",
       "        3.69871825e-02, 1.79603168e-07]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "logit.predict_proba(features_test)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Threshold:', threshold[116])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.6 Evaluating Multiclass Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a model that predicts three or more classes and want to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83653269, 0.8259826 , 0.81308131])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=3,\n",
    "                                       n_informative=3,\n",
    "                                       n_redundant=0,\n",
    "                                       n_classes=3,\n",
    "                                       random_state=1)\n",
    "# Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "# Cross-validate model using accuracy\n",
    "cross_val_score(logit, features, target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83613125, 0.82562258, 0.81293539])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.7 Visualizing a Classifier's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given predicted classes and true classes of the test data, you want to visually compare the model's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 180]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0ae8d3d09b0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtarget_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Create confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 180]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "# Create feature matrix\n",
    "features = iris.data\n",
    "# Create target vector \n",
    "target = iris.target\n",
    "# Create list of target class names\n",
    "class_names = iris.target_names\n",
    "# Create training and test set\n",
    "features_train, features_test, target_train,\n",
    "target_test = train_test_split(features, target, random_state=1)\n",
    "# Create logistic regression \n",
    "logit = LogisticRegression()\n",
    "# Train model and make predictions\n",
    "target_predicted = classifier.fit(features_train, target_train).predict(features_test)\n",
    "# Create confusion matrix\n",
    "matrix = confusion_matrix(target_test, target_predicted)\n",
    "# Create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "# Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap='Blues')\n",
    "plt.title('Confusion Matrix'), plt.tight_layout()\n",
    "plt.ylabel('True Class'), plt.xlabel('Predicted Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.8 Evaluating Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1718.22817783, -3103.4124284 , -1377.17858823])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate features matrix, target vector\n",
    "features, target = make_regression(n_samples=100,\n",
    "                                   n_features=3,\n",
    "                                   n_informative=3,\n",
    "                                   n_targets=1,\n",
    "                                   noise=50,\n",
    "                                   coef=False,\n",
    "                                   random_state=1)\n",
    "# Create a linear regression object\n",
    "ols = LinearRegression()\n",
    "# Cross-validate the linear regression using (negative) MSE\n",
    "cross_val_score(ols, features, target, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87804558, 0.76395862, 0.89154377])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate the linear regression using R-squared\n",
    "cross_val_score(ols, features, target, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.9 Evaluating Clustering Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have an unsupervised learning algorithm to cluster my data.\n",
    "\n",
    "Now I want to know how well it did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916265564072142"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate feature matrix \n",
    "features, _ = make_blobs(n_samples=1000,\n",
    "                         n_features=10,\n",
    "                         centers=2,\n",
    "                         cluster_std=0.5,\n",
    "                         shuffle=True,\n",
    "                         random_state=1)\n",
    "# Cluster data using k-means to predict classes\n",
    "model = KMeans(n_clusters=2, random_state=1).fit(features)\n",
    "# Get predicted classes \n",
    "target_predicted = model.labels_\n",
    "# Evaluate model \n",
    "silhouette_score(features, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.10 Creating a Custom Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to evaluate a model using a metric I created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 180]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-31d5372ef7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Apply custom scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 98\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-31d5372ef7c2>\u001b[0m in \u001b[0;36mcustom_metric\u001b[0;34m(target_test, target_predicted)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Calculate r-squared score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Returen r-squared score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    535\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 180]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples=100,\n",
    "                                   n_features=3,\n",
    "                                   random_state=1)\n",
    "# Create training set and test set\n",
    "features_train, features_test, target_train, \n",
    "target_test = train_test_split(features, target, \n",
    "                               test_size=0.1, random_state=1)\n",
    "# Create custom metric\n",
    "def custom_metric(target_test, target_predicted):\n",
    "    # Calculate r-squared score\n",
    "    r2 = r2_score(target_test, target_predicted)\n",
    "    # Returen r-squared score\n",
    "    return r2\n",
    "# Make scorer and define that higher scores are better \n",
    "score = make_scorer(custom_metric, greater_is_better=True)\n",
    "# Create ridge regression object\n",
    "classifier = Ridge()\n",
    "# Train ridge regression model\n",
    "model = classifier.fit(features_train, target_train)\n",
    "# Apply custom scorer\n",
    "score(model, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 180]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-ab6314624c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calculate r-squared score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    535\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 180]"
     ]
    }
   ],
   "source": [
    "# Predicted values\n",
    "target_predicted = model.predict(features_test)\n",
    "# Calculate r-squared score\n",
    "r2_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.11 Visualizing the Effect of Training Set Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2865e978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Load data\n",
    "digits = load_digits()\n",
    "# Create feature matrix and target vector\n",
    "features, target = digits.data, digits.target\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(# Classifier\n",
    "                                                        RandomForestClassifier(),\n",
    "                                                        # Feature Matrix\n",
    "                                                        features,\n",
    "                                                        # Target Vector\n",
    "                                                        target,\n",
    "                                                        # Number of folds\n",
    "                                                        cv=10,\n",
    "                                                        # Performance Metric\n",
    "                                                        scoring='accuracy',\n",
    "                                                        # Use all cpu\n",
    "                                                        n_jobs=-1,\n",
    "                                                        # Size of 50\n",
    "                                                        # Training set\n",
    "                                                        train_sizes=np.linspace(\n",
    "                                                        0.01,\n",
    "                                                        1.0,50))\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '-o', \n",
    "         color='blue', label='Training Score')\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='red', label='Cross-validation Score')\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std,\n",
    "                 train_mean + train_std, color='#DDDDDD')\n",
    "plt.fill_between(train_sizes, test_mean - test_std,\n",
    "                 test_mean + test_std, color='#DDDDDD')\n",
    "# Create plot\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Set Size'), plt.ylabel('Accuracy Score'), \n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.12 Creating a Text Report of Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want a quick description of a classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 180]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-69bac4ac7630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m print(classification_report(target_test,\n\u001b[1;32m     24\u001b[0m                             \u001b[0mtarget_predicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                             target_names=class_names))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \"\"\"\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 180]"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "# Create feature matrix\n",
    "features = iris.data\n",
    "# Create target vector\n",
    "target = iris.target\n",
    "# Create list of target class names\n",
    "class_names = iris.target_names\n",
    "# Create training set and test set\n",
    "features_train, features_test, target_train, \n",
    "target_test = train_test_split(features, target, random_state=1)\n",
    "# Create logistic regression\n",
    "classifier = LogisticRegression()\n",
    "# Train model and make prediction\n",
    "model = classifier.fit(features_train, target_train)\n",
    "target_predicted = model.predict(features_test)\n",
    "# Create a classification report\n",
    "print(classification_report(target_test,\n",
    "                            target_predicted,\n",
    "                            target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.13 Visualizing the Effect of Hyperparameter Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wnat to understand how the performance of a model changes as the value of some hyperparameter changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [150, 1797]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-cfb6d7b756b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                                              \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                              \u001b[0;31m# Use all cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                              n_jobs = -1)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m# Calculate means and standard deviations of training set scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtrain_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mvalidation_curve\u001b[0;34m(estimator, X, y, param_name, param_range, groups, cv, scoring, n_jobs, pre_dispatch, verbose, error_score)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \"\"\"\n\u001b[0;32m-> 1435\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [150, 1797]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Load data\n",
    "digits = load_digits()\n",
    "# Create feature matrix and target vector\n",
    "feature, target = digits.data, digits.target\n",
    "# Create range of values for parameter\n",
    "param_range = np.arange(1, 250, 2)\n",
    "# Calculate accuracy on training and test set using range of parameter values\n",
    "train_scores, test_scores = validation_curve(# Classifier\n",
    "                                             RandomForestClassifier(),\n",
    "                                             # Feature Matrix\n",
    "                                             features,\n",
    "                                             # Target Vector\n",
    "                                             target,\n",
    "                                             # Hyperparameter to examine\n",
    "                                             param_name='n_estimators',\n",
    "                                             # Range of hyperparameter's values\n",
    "                                             param_range=param_range,\n",
    "                                             # Number of folds\n",
    "                                             cv = 3,\n",
    "                                             # Performance Metric\n",
    "                                             scoring='accuracy',\n",
    "                                             # Use all cpu\n",
    "                                             n_jobs = -1)\n",
    "# Calculate means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "# Plot mean accuracy scores for training and test sets\n",
    "plt.plot(param_range, train_mean, \n",
    "         label='Training Score', color='black')\n",
    "plt.plot(param_range, test_mean, \n",
    "         label='Cross-validation Score', color='dimgrey')\n",
    "# Plot accuracy bands for training and test sets\n",
    "plt.fill_between(param_range, train_mean - train_std,\n",
    "                 train_mean + train_std, color='gray')\n",
    "plt.fill_between(param_range, test_mean - test_std,\n",
    "                 test_mean + test_std, color='gainsboro')\n",
    "# Create plot\n",
    "plt.title('Validation Curve With Random Forest')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
